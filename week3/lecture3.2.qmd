---
title: "Lecture 3.2"
editor_options: 
  chunk_output_type: console
---

## Setup

```{r}
#..........................load packages.........................
library(tidyverse)
library(chron)
library(naniar)

#..........................import data...........................
mko <- read_csv("https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-sbc.2007.17&entityid=02629ecc08a536972dec021f662428aa")

```

## Wrangle

```{r}
mko_clean <- mko |>
# keep only necesary columns ----
  select(year, month, day, decimal_time, Temp_bot, Temp_top, Temp_mid) |>

  # create datetime column (not totally necessary for our plots, but it can helpful to know how to do this!) ----
  unite(date, year, month, day, sep = "-", remove = FALSE) |>
  mutate(time = chron::times(decimal_time)) |>
  unite(date_time, date, time, sep = " ") |>

  # coerce data types ----
  mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"), # see <https://www.neonscience.org/resources/learning-hub/tutorials/dc-convert-date-time-posix-r> for overview of POSIXct vs POSIXlt
         year = as.factor(year),
         month = as.factor(month),
         day = as.numeric(day)) |>

  # add month name by indexing the built-in `month.name` vector ----
  mutate(month_name = as.factor(month.name[month])) |>

  # replace 9999s with NAs ----
  naniar::replace_with_na(replace = list(Temp_bot = 9999, 
                                         Temp_top = 9999, 
                                         Temp_mid = 9999)) |>

  # select/reorder desired columns ----
  select(date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)

```

```{r}
#......................explore missing data......................

# counts and percentage of missing data by year ----
see_NAs <- mko_clean |> 
  group_by(year) |> 
  naniar::miss_var_summary() |>
  filter(variable == "Temp_bot")

# visualize missing Temp_bot ----
bottom <- mko_clean |> select(Temp_bot)
missing_temps <- naniar::vis_miss(bottom)
```

## Histograms

```{r}
mko_clean |> 
  mutate(month_name = factor(month_name, levels = month.name)) |> 
  filter(month_name %in% c("April", "June", "October")) |> 
  ggplot(aes(x = Temp_bot, fill = month_name)) + 
  geom_histogram(position = "identity", alpha = 0.5, binwidth = .2) +
  scale_fill_manual(values = c("#2C5374", "#ADD8E6", "#8B3A3A"))
```

## Density Plots

```{r}
mko_clean |> 
  filter(month_name %in% c("April", "June", "October")) |> 
  ggplot(aes(x = Temp_bot, fill = month_name)) +
  geom_density(alpha = 0.5, adjust = .8) + 
  scale_fill_manual(values = c("#2C5374", "#ADD8E6", "#8B3A3A"))
```

## Ridgeline Plots

```{r}
ggplot(mko_clean, aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +
  ggridges::geom_density_ridges_gradient(rel_min_height = 0.01, scale = 3) +
  scale_y_discrete(limits = rev(month.name)) +
  scale_fill_gradientn(colors = c("#2C5374","#849BB4", "#D9E7EC", "#EF8080", "#8B3A3A"))
```

## Box Plots

```{r}
ggplot(mko_clean, aes(x = month_name, y = Temp_bot, fill = month_name)) +
  geom_boxplot() +
  scale_x_discrete(limits = rev(month.name)) +
  coord_flip() +
  gghighlight::gghighlight(month_name == "October") +
  theme( legend.position = "name")
```

```{r}
# Jitter & dodge
library(palmerpenguins)

penguins %>% 
  mutate(year = as.factor(year)) %>% 
  ggplot(aes(x = species, y = body_mass_g, color = year)) +
  geom_boxplot() +
  geom_point(alpha = 0.5, position = position_jitterdodge(jitter.width = 0.2)) +
  coord_flip()
```

## Violin Plots

```{r}
ggplot(mko_clean, aes(x = month_name, y = Temp_bot)) +
  geom_violin() +
  geom_boxplot(color = "gray", alpha = 0.5, width = 0.2, outlier.color = "black") +
  scale_x_discrete(limits = rev(month.name)) +
  coord_flip()
```

```{r}
# half and half
ggplot(penguins, aes(x = species, y = bill_length_mm,
                     fill = species)) +
  see::geom_violindot(size_dots = 5, alpha = 0.5)
```

## Setup

```{r}
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                    setup                                 ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#.........................load libraries.........................
library(tidycensus)
library(tidyverse)
library(janitor)
library(gghighlight)

#.........................source API key.........................
source(here::here("week3", "KEYS.R"))
census_api_key(censusKEY)

#..........................import data...........................
lyme <- read_csv(here::here("week3", "data", "LD-Case-Counts-by-County-01-20.csv"))

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                          wrangle lyme disease data                       ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#............wide to long (plus some other wrangling)............
lyme_clean <- lyme |> 
  
  # make col names snake_case ----
  janitor::clean_names() |> 
  
  # rename columns ----
  rename(county = ctyname, state = stname, status = ststatus) |> 
  
  # wide to long (tidy) years
  pivot_longer(cols = 6:25, names_to = "county_year", values_to = "reported_cases") |> 
  
  # remove "cases" from the year & coerce year from chr to factor ----
  mutate(year = str_remove(county_year, pattern = "cases"),
         year = as.factor(year)) |> 
  
  # select necessary cols ----
  select(year, county, state, status, reported_cases)

#................calculate total cases per state.................
lyme_by_state <- lyme_clean |> 
  group_by(year, state) |> 
  summarize(total_cases = sum(reported_cases)) 

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                      request / wrangle population data                   ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#...................get pop estimates by state...................
us_state_pop <- get_estimates(geography = "state", 
                              product = "population",
                              state = NULL, 
                              year = 2019) |> 
  filter(variable == "POP") |> 
  select(state = NAME, population = value) 

#........................write data to csv.......................
# optional, but recommended in case you want to work offline, the API is down, etc. (you can then read in your saved data file rather than run the above code)
# write_csv(us_state_pop, file = here::here("week3", "data", "us_state_pop.csv"))

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                            join lyme & pop dfs                           ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

lyme_pop <- left_join(lyme_by_state, us_state_pop) |> 
  
  # add col with num of 100k people per state ----
  mutate(pop100k = population/100000) |> 
  
  # calculate num cases per 100k people (common way of reporting disease incidence) ----
  mutate(cases_per100k = total_cases/pop100k) 
```
