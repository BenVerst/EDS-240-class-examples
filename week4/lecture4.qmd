Continued week 3 at bottom\

```{r}
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                    setup                                 ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#..........................load packages.........................
library(tidyverse)

#..........................import data...........................
jobs <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv")

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                wrangle data                              ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

jobs_clean <- jobs |> 
  
  # add cols (needed for dumbbell plot) ----
  mutate(percent_male = 100 - percent_female, # % of females within each industry was already included
         difference_earnings = total_earnings_male - total_earnings_female) |>  # diff in earnings between M & F
  
  # rearrange columns ----
  relocate(year, major_category, minor_category, occupation,
          total_workers, workers_male, workers_female,
          percent_male, percent_female,
          total_earnings, total_earnings_male, total_earnings_female, difference_earnings,
          wage_percent_of_male) |> 
  
  # drop rows with missing earning data ----
  drop_na(total_earnings_male, total_earnings_female) |> 
  
  # make occupation a factor ----
  mutate(occupation = as.factor(occupation)) |> 
  
  # ---- this next step is for creating our dumbbell plots ----

  # classify jobs by percentage male or female ----
  mutate(group_label = case_when(
    percent_female >= 75 ~ "Occupations that are 75%+ female",
    percent_female >= 45 & percent_female <= 55 ~ "Occupations that are 45-55% female",
    percent_male >= 75 ~ "Occupations that are 75%+ male"
  )) 
```

## Bar/lollipop Plot

```{r}
jobs_clean |> 
  filter(year == 2016) |> 
  slice_max(order_by = total_earnings, n = 10) |> 
  ggplot(aes(x = fct_reorder(occupation, total_earnings), y = total_earnings)) +
  ggalt::geom_lollipop() +
  geom_text(aes(label = scales::dollar(total_earnings)), hjust = -0.2) + 
  scale_y_continuous(labels = scales::label_currency(accuracy = 1, scale = 0.001, suffix = "k"),
                     limits = c(0, 250000)) + # expand axis to make room for values
  coord_flip()

# two groups ----
jobs_clean |> 
  filter(year == 2016) |> 
  slice_max(order_by = total_earnings, n = 10) |> 
  pivot_longer(cols = c(total_earnings_female, total_earnings_male), names_to = "group", values_to = "earnings_by_group") |> 
  mutate(sex = str_remove(group, pattern = "total_earnings_")) |> 
  ggplot(aes(x = fct_reorder(occupation, earnings_by_group), y = earnings_by_group, fill = sex)) + 
  geom_col(position = position_dodge()) + # default `position = "stack"`
  coord_flip()

# two groups lollipop ----
jobs_clean |>
  filter(year == 2016) |>
  slice_max(order_by = total_earnings, n = 10) |>
  pivot_longer(cols = c(total_earnings_female, total_earnings_male), names_to = "group", values_to = "earnings_by_group") |>
  mutate(sex = str_remove(group, pattern = "total_earnings_")) |>
  ggplot(aes(x = fct_reorder(occupation, earnings_by_group), y = earnings_by_group, color = sex)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_linerange(aes(xmin = occupation, xmax = occupation, 
                     ymin = 0, ymax = earnings_by_group),
                 position = position_dodge(width = 0.5)) +
  coord_flip()
```

## Dumbell Plot

```{r}
#....guarantee the same random samples each time we run code.....
set.seed(0)

#.........get 10 random jobs that are 75%+ female (2016).........
f75 <- jobs_clean |> 
  filter(year == 2016, group_label == "Occupations that are 75%+ female") |> 
  slice_sample(n = 10)

#..........get 10 random jobs that are 75%+ male (2016)..........
m75 <- jobs_clean |> 
  filter(year == 2016, group_label == "Occupations that are 75%+ male") |> 
  slice_sample(n = 10)

#........get 10 random jobs that are 45-55%+ female (2016).......
f50 <- jobs_clean |> 
  filter(year == 2016, group_label == "Occupations that are 45-55% female") |> 
  slice_sample(n = 10)

#.......combine dfs & relevel factors (for plotting order).......
subset_jobs <- rbind(f75, m75, f50) |> 
  mutate(group_label = fct_relevel(group_label, "Occupations that are 75%+ female",
                                   "Occupations that are 45-55% female",
                                   "Occupations that are 75%+ male")) 
```

```{r}
# dumbell plot ----
ggplot(subset_jobs) + 
  geom_segment(aes(x = total_earnings_female,
                   xend = total_earnings_male,
                   y = fct_reorder(occupation, total_earnings), yend = occupation)) +
  geom_point(aes(x = total_earnings_male, y = occupation),
             color = "darkolivegreen", size = 1.5) +
  geom_point(aes(x = total_earnings_female, y = occupation),
             color = "maroon2", size = 1.5) +
  facet_wrap(~group_label, nrow = 3, scales = "free_y")
  
```

# Visualizing Relationships

```{r}
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                    setup                                 ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#..........................load packages.........................
library(metajam) 
library(tidyverse)

#...................download data from DataOne...................
download_d1_data("https://cn.dataone.org/cn/v2/resolve/https%3A%2F%2Fpasta.lternet.edu%2Fpackage%2Fdata%2Feml%2Fknb-lter-hbr%2F208%2F9%2F3b3cf7ea447cb875d7c7d68ebdfd24c7",
                 path = here::here("MEDS", "MEDS_240", "EDS-240-class-examples", "week4")) 

#  ~ NOTE: I recommend renaming the downloaded folder to 'data/' so that it's ignored by .gitignore! ~

#....................read in downloaded files....................
stream_chem_all <- read_d1_files(here::here("MEDS", "MEDS_240", "EDS-240-class-examples", "week4", "data"))

#........................get the data file.......................
stream_chem_data <- stream_chem_all$data
```

## Basic Scatterplot

```{r}
stream_chem_data %>% 
  filter(waterYr == 2021) %>% 
  ggplot(aes(x = DOC, y = pH)) +
  geom_point(alpha = 0.5) +
  geom_rug()

# ggExtra
p1 <- stream_chem_data %>% 
  filter(waterYr == 2021) %>% 
  ggplot(aes(x = DOC, y = pH)) +
  geom_point(alpha = 0.5)

ggExtra::ggMarginal(p1, type = "histogram", # can do density, boxplot, and others 
                    margins = "x"
                    )


#ggExtra(mulitple groups)
p2 <- stream_chem_data %>% 
  filter(waterYr == 2021) %>% 
  ggplot(aes(x = DOC, y = pH, color = site)) +
  geom_point(alpha = 0.5)+
  theme(legend.position = "bottom")

ggExtra::ggMarginal(p2, type = "histogram", # can do density, boxplot, and others 
                    #margins = "x"
                    groupFill = TRUE, groupColour = TRUE)
```

```{r}
stream_chem_data |> 
  filter(waterYr == 2021) |> 
  filter(site == "W8") |> 
  ggplot(aes(x = DOC, y = pH)) + 
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE)
```

```{r}
stream_chem_data |> 
  filter(waterYr == 2021) |>
  ggplot(aes(x = DOC, y = pH, color = site, size = Al_ICP)) + 
  geom_point(alpha = 0.5) 
```

Continuing from week 3

```{r}
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                    setup                                 ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#.........................load libraries.........................
library(tidycensus)
library(tidyverse)
library(janitor)
library(gghighlight)

#.........................source API key.........................
source(here::here("MEDS", "MEDS_240", "EDS-240-class-examples", "week3", "KEYS.R"))
census_api_key(censusKEY)

#..........................import data...........................
lyme <- read_csv(here::here("MEDS", "MEDS_240", "EDS-240-class-examples", "week3", "data", "LD-Case-Counts-by-County-01-20.csv"))

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                          wrangle lyme disease data                       ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#............wide to long (plus some other wrangling)............
lyme_clean <- lyme |> 
  
  # make col names snake_case ----
  janitor::clean_names() |> 
  
  # rename columns ----
  rename(county = ctyname, state = stname, status = ststatus) |> 
  
  # wide to long (tidy) years
  pivot_longer(cols = 6:25, names_to = "county_year", values_to = "reported_cases") |> 
  
  # remove "cases" from the year & coerce year from chr to factor ----
  mutate(year = str_remove(county_year, pattern = "cases"),
         year = as.factor(year)) |> 
  
  # select necessary cols ----
  select(year, county, state, status, reported_cases)

#................calculate total cases per state.................
lyme_by_state <- lyme_clean |> 
  group_by(year, state) |> 
  summarize(total_cases = sum(reported_cases)) 

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                      request / wrangle population data                   ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#...................get pop estimates by state...................
us_state_pop <- get_estimates(geography = "state", 
                              product = "population",
                              state = NULL, 
                              year = 2019) |> 
  filter(variable == "POP") |> 
  select(state = NAME, population = value) 

#........................write data to csv.......................
# optional, but recommended in case you want to work offline, the API is down, etc. (you can then read in your saved data file rather than run the above code)
# write_csv(us_state_pop, file = here::here("week3", "data", "us_state_pop.csv"))

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                            join lyme & pop dfs                           ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

lyme_pop <- left_join(lyme_by_state, us_state_pop) |> 
  
  # add col with num of 100k people per state ----
  mutate(pop100k = population/100000) |> 
  
  # calculate num cases per 100k people (common way of reporting disease incidence) ----
  mutate(cases_per100k = total_cases/pop100k) 
```

## Line Plot

```{r}
# highlight ----
lyme_pop %>% 
  filter(year %in% c(2010:2020)) %>% 
  ggplot(aes(x = year, y = cases_per100k, group = state, color = state)) +
  geom_line() +
  gghighlight::gghighlight(state == "New Jersey")
  
# highlight based on a conditional ----
lyme_pop %>% 
  filter(year %in% c(2010:2020)) %>% 
  ggplot(aes(x = year, y = cases_per100k, group = state, color = state)) +
  geom_line() +
  gghighlight::gghighlight(max(cases_per100k) > 100)

# aspect ratio ----
lyme_pop |> 
  filter(year %in% c(2010:2020)) |> 
  filter(state == "Vermont") |> 
  ggplot(aes(x = year, y = cases_per100k, group = state)) +
  geom_line() +
  #scale_y_continuous(breaks = seq(0, 190, by = 1)) +
  coord_fixed(ratio = 1/50)
```

## Area Plots

```{r}
lyme_pop |> 
  filter(year %in% c(2010:2020)) |> 
  filter(state == "New Jersey") |> 
  ggplot(aes(x = year, y = cases_per100k, group = state, fill = state)) +
  geom_area() +
  scale_fill_manual(values = c("darkseagreen4")) +
  scale_x_discrete(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme(legend.position = "none")


# stacked area chart ----
lyme_pop |> 
  filter(year %in% c(2010:2020)) |> 
  filter(state %in% c("Maine", "Rhode Island", "New Hampshire", "Vermont")) |> 
  ggplot(aes(x = year, y = cases_per100k, group = state, fill = state)) +
  geom_area(position = "fill") +
  scale_y_continuous(labels = scales::label_percent(scale = 100))

# 4 separate line charts ----
lyme_pop |> 
  filter(year %in% c(2010:2020)) |> 
  filter(state %in% c("Maine", "Rhode Island", "New Hampshire", "Vermont")) |> 
  ggplot(aes(x = year, y = cases_per100k, group = state, color = state)) +
  geom_line() +
  facet_wrap(~state)
```
